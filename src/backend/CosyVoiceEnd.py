import sys
import os
from pathlib import Path

# ================= é…ç½®è·¯å¾„ (æœ€å…³é”®çš„æ­¥éª¤) =================
# 1. è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„
current_file_path = Path(__file__).resolve()

project_root = current_file_path.parent.parent.parent

# 3. å®šä½ CosyVoice çš„æ ¹ç›®å½•
cosyvoice_root = project_root / "model" / "tts" / "CosyVoice"

# 4. æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨ (æ–¹ä¾¿è°ƒè¯•)
if not cosyvoice_root.exists():
    raise FileNotFoundError(f"æ‰¾ä¸åˆ° CosyVoice ç›®å½•ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {cosyvoice_root}")

# 5. å°† CosyVoice ç›®å½•åŠ å…¥ç³»ç»Ÿè·¯å¾„ï¼Œè¿™æ · Python æ‰èƒ½æ‰¾åˆ° cosyvoice åŒ…
sys.path.insert(0, str(cosyvoice_root))

# æ³¨æ„ï¼šCosyVoice ç»å¸¸ä¾èµ– third_party ä¸‹çš„æ¨¡å— (å¦‚ Matcha-TTS)ï¼Œä¹Ÿéœ€è¦åŠ ä¸Š
matcha_path = cosyvoice_root / "third_party" / "Matcha-TTS"
if matcha_path.exists():
    sys.path.append(str(matcha_path))

from fastapi import FastAPI,Form,UploadFile,File
from fastapi.responses import StreamingResponse
from cosyvoice.cli.cosyvoice import AutoModel

import tempfile
import torch
import torchaudio
import io
import soundfile as sf

model_dir = cosyvoice_root / "pretrained_models" / "CosyVoice2-0.5B"

app = FastAPI()

print("æ­£åœ¨åŠ è½½ CosyVoice2 æ¨¡å‹")
model = AutoModel(model_dir=str(model_dir))
print("æ¨¡å‹åŠ è½½å®Œæˆ")

@app.post("/tts")
async def TTS(
    tar_text: str = Form(...),
    tar_lang: str = Form(...),
    prompt_audio: UploadFile = File(...),
    prompt_text: str = Form(...)
    ):
    """
    æ¥æ”¶ç›®æ ‡æ–‡æœ¬ã€å‚è€ƒæ–‡æœ¬å’Œå‚è€ƒéŸ³é¢‘ï¼Œè¿›è¡Œé›¶æ ·æœ¬è¯­éŸ³å…‹éš†
    """
    prompt_wav_path = ""
    try:
        # 1. å°†ä¸Šä¼ çš„éŸ³é¢‘ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ï¼Œå› ä¸ºCosyVoiceè¯»å–çš„æ˜¯æ–‡ä»¶è·¯å¾„
        suffix = os.path.splitext(prompt_audio.filename)[-1]
        if not suffix:
            suffix = ".wav"
            
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            content = await prompt_audio.read()
            tmp.write(content)
            prompt_wav_path = tmp.name

        # 2. è°ƒç”¨ CosyVoice2 è¿›è¡Œæ¨ç†
        # inference_zero_shot å‚æ•°: (ç›®æ ‡æ–‡æœ¬, å‚è€ƒéŸ³é¢‘æ–‡æœ¬, å‚è€ƒéŸ³é¢‘è·¯å¾„)
        # æ³¨æ„ï¼šè¿™é‡Œè¿”å›çš„æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œæˆ‘ä»¬éœ€è¦è·å–ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®
        # å¦‚æœæ˜¯çŸ­æ–‡æœ¬ï¼Œé€šå¸¸åªæœ‰ä¸€ä¸ªç”Ÿæˆç»“æœ
        
        audio = None

        print("ğŸ“¦ ä¸´æ—¶éŸ³é¢‘å¤§å°:", os.path.getsize(prompt_wav_path))

        waveform, sr = torchaudio.load(prompt_wav_path)
        print("ğŸ§ torchaudio load success:", waveform.shape, sr)

        # ä½¿ç”¨ inference_zero_shot è¿›è¡Œå…‹éš†
        # stream=False è¡¨ç¤ºä¸€æ¬¡æ€§ç”Ÿæˆï¼Œé€‚åˆéæµå¼API
        print("è¯­éŸ³ç”Ÿæˆå¼€å§‹")
        
        instruct_text = f"ç”¨{tar_lang}è¯´è¿™å¥è¯<|endofprompt|>"
        
        responses = model.inference_instruct2(tar_text, instruct_text, prompt_wav_path, stream=False)
        
        for response in responses:
            audio = response['tts_speech']
            # è¿™é‡Œæˆ‘ä»¬åªå–ç¬¬ä¸€æ®µç»“æœï¼ˆå¦‚æœæ–‡æœ¬å¾ˆé•¿å¯èƒ½éœ€è¦æ‹¼æ¥ï¼‰
            break 

        if audio is None:
            return {"error": "Generation failed"}

        # 3. å°† Tensor è½¬æ¢ä¸º Bytes (WAVæ ¼å¼) è¿”å›
        buffer = io.BytesIO()
        audio_numpy = audio.cpu().squeeze().numpy()
        sf.write(buffer, audio_numpy, model.sample_rate, format='WAV')
        # torchaudio.save(buffer, audio.cpu(), model.sample_rate, format="wav")
        buffer.seek(0)

        return StreamingResponse(buffer, media_type="audio/wav")

    except Exception as e:
        return {"error": str(e)}
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if prompt_wav_path and os.path.exists(prompt_wav_path):
            os.remove(prompt_wav_path)


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=6008)

